# DocuChat AI ğŸ¤–ğŸ“„

A modern, AI-powered document chat application that allows users to upload PDF documents and have natural conversations with their content using advanced language models.

## âœ¨ Features

- **ğŸ“¤ PDF Upload**: Easy drag-and-drop interface for uploading PDF documents
- **ğŸ§  AI-Powered Chat**: Chat with your documents using OpenAI GPT-4o-mini or Google Gemini 2.0 Flash
- **ğŸ” Semantic Search**: Uses vector embeddings and Pinecone for intelligent document retrieval
- **ğŸ’¬ Streaming Responses**: Real-time streaming of AI responses for better UX
- **ğŸ“š Source Attribution**: View the exact document chunks used to generate each answer
- **ğŸ’¾ Persistent History**: Chat history saved in browser localStorage
- **ğŸ¨ Modern UI**: Beautiful, responsive interface built with Tailwind CSS 4
- **ğŸŒ™ Dark Theme**: Elegant neutral color scheme optimized for readability

## ğŸ—ï¸ Architecture

### RAG Pipeline

The application implements a complete Retrieval-Augmented Generation (RAG) pipeline:

1. **Document Processing**
   - PDF parsing using `pdf-parse-fork`
   - Text chunking with configurable size (1000 chars) and overlap (200 chars)

2. **Embedding Generation**
   - Uses OpenAI's `text-embedding-3-small` model
   - Generates 1536-dimensional vector embeddings

3. **Vector Storage**
   - Stores embeddings in Pinecone vector database
   - Cosine similarity metric for semantic search
   - Metadata includes source file and chunk index

4. **Retrieval & Generation**
   - Queries Pinecone for top 5 relevant chunks
   - Passes context to LLM (OpenAI or Gemini)
   - Streams responses in real-time

## ğŸš€ Tech Stack

### Frontend
- **Next.js 16.0.1** - React framework with App Router
- **React 19** - UI library
- **TypeScript 5** - Type safety
- **Tailwind CSS 4** - Utility-first styling
- **Lucide React** - Icon library

### Backend & AI
- **Vercel AI SDK** - Unified AI interface
- **OpenAI API** - GPT-4o-mini for chat & embeddings
- **Google Gemini API** - Gemini 2.0 Flash model
- **Pinecone** - Vector database for embeddings
- **pdf-parse-fork** - PDF text extraction

### Development
- **ESLint** - Code linting
- **PostCSS** - CSS processing

## ğŸ“‹ Prerequisites

- Node.js 18+ installed
- npm or yarn package manager
- API keys for:
  - OpenAI API
  - Pinecone
  - Google AI (for Gemini)

## ğŸ”§ Installation

1. **Clone the repository**
```bash
git clone https://github.com/LakshayJ17/rag-assignment.git
cd buildfast-assignment
```

2. **Install dependencies**
```bash
npm install
```

3. **Set up environment variables**

Create a `.env` file in the root directory:

```env
# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=your_index_name

# Google AI (for Gemini)
GOOGLE_GENERATIVE_AI_API_KEY=your_google_ai_key_here
```

4. **Run the development server**
```bash
npm run dev
```

5. **Open your browser**
Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“ Project Structure

```
buildfast-assignment/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts          # Chat API endpoint
â”‚   â”‚   â””â”€â”€ upload/
â”‚   â”‚       â””â”€â”€ route.ts          # PDF upload API endpoint
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â””â”€â”€ page.tsx              # Chat interface page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx     # Message bubble component
â”‚   â”‚   â””â”€â”€ Header.tsx            # Navigation header
|   |   â””â”€â”€ ThemeToggle.tsx       # Theme Toggle
â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â””â”€â”€ page.tsx              # Upload interface page
â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â”œâ”€â”€ layout.tsx                # Root layout
â”‚   â””â”€â”€ page.tsx                  # Landing page
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ chunkText.ts              # Text chunking utility
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ stream.ts              
â”œâ”€â”€ public/                       # Static assets
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ next.config.ts
```

## ğŸ¯ Usage

### 1. Upload a PDF Document

- Click "Upload PDF" on the landing page
- Select a PDF file from your device
- Wait for processing (parsing â†’ chunking â†’ embedding â†’ storage)
- Click "Start Chat" once upload is complete

### 2. Chat with Your Document

- Enter your question in the chat input
- Select AI model (OpenAI or Gemini)
- Watch the AI stream its response in real-time
- View source citations below each answer
- Clear chat history anytime with "Clear chat" button

### 3. Model Selection

Switch between two powerful AI models:
- **OpenAI (GPT-4o-mini)**: Fast, cost-effective, excellent reasoning
- **Gemini (2.0 Flash)**: Google's latest model with strong performance

## ğŸ”‘ Key Features Explained

### Streaming Responses
The application uses Vercel AI SDK's `streamText()` for real-time response streaming, providing instant feedback as the AI generates answers.

### Source Attribution
Each answer includes references to the original document chunks used, with:
- First 200 characters of each source chunk
- Source filename
- Up to 5 relevant chunks per query

### Smart Chunking
Documents are split into overlapping chunks (1000 chars with 200 char overlap) to maintain context across chunk boundaries.

### Persistent Chat History
Conversations are automatically saved to browser localStorage, persisting across page refreshes.

## ğŸ› ï¸ API Endpoints

### POST `/api/upload`
Upload and process a PDF document.

**Request:**
- `Content-Type: multipart/form-data`
- Body: `file` (PDF file)

**Response:**
```json
{
  "success": true,
  "message": "File successfully uploaded. Start chatting.."
}
```

### POST `/api/chat`
Send a query and receive streaming AI response.

**Request:**
```json
{
  "query": "What is this document about?",
  "model": "openai" // or "gemini"
}
```

**Response:**
- Streaming text response
- `X-Sources` header with base64-encoded source chunks

## ğŸ¨ Styling & Design

- **Neutral Dark Theme**: Professional dark mode with neutral-900 background
- **Responsive Design**: Fully responsive from mobile to desktop
- **Gradient Accents**: Emerald-to-blue gradients for branding
- **Smooth Animations**: Hover effects and transitions throughout
- **Accessible**: Focus states and semantic HTML

## ğŸš¦ Scripts

```bash
# Development server
npm run dev

# Production build
npm run build

# Start production server
npm start

# Lint code
npm run lint
```

## ğŸ› Troubleshooting

### "Invalid JSON" Error
- Ensure your `.env.local` file has all required API keys
- Check that Pinecone index exists or allow auto-creation

### PDF Upload Fails
- Verify PDF is not password-protected
- Check file size (large PDFs may timeout)
- Ensure OpenAI and Pinecone API keys are valid

### No Responses from Chat
- Verify vectors were successfully uploaded to Pinecone
- Check browser console for API errors
- Confirm model name is correct ("openai" or "gemini")

### Dev Server Won't Start
- Remove trailing commas from `package.json` if present
- Clear `.next` folder: `rm -rf .next` (or `rmdir /s .next` on Windows)
- Delete `node_modules` and reinstall: `npm install`

## ğŸ“ Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for embeddings and chat | Yes |
| `PINECONE_API_KEY` | Pinecone API key for vector storage | Yes |
| `PINECONE_INDEX_NAME` | Name of your Pinecone index | Yes |
| `GOOGLE_GENERATIVE_AI_API_KEY` | Google AI API key for Gemini | Yes |

## ğŸ” Security Notes

- API keys are server-side only (not exposed to client)
- File uploads are validated for type and content
- No sensitive data is stored in localStorage
- Consider adding authentication for production use

## ğŸš€ Deployment

### Vercel (Recommended)

1. Push your code to GitHub
2. Connect repository to Vercel
3. Add environment variables in Vercel dashboard
4. Deploy!

### Other Platforms

Ensure your hosting platform supports:
- Node.js 18+
- Environment variables
- Serverless functions or Node.js runtime

## ğŸ“¦ Dependencies

### Production
- `next`: ^16.0.1
- `react`: ^19.2.0
- `@ai-sdk/openai`: ^2.0.65
- `@ai-sdk/google`: ^2.0.31
- `ai`: ^5.0.93
- `@pinecone-database/pinecone`: ^6.1.3
- `openai`: ^6.8.1
- `pdf-parse-fork`: ^1.2.0
- `lucide-react`: ^0.553.0
- `tailwindcss`: ^4.1.17

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is for educational/assignment purposes.

## ğŸ™ Acknowledgments

- Built with [Next.js](https://nextjs.org/)
- AI powered by [OpenAI](https://openai.com/) and [Google Gemini](https://deepmind.google/technologies/gemini/)
- Vector search by [Pinecone](https://www.pinecone.io/)
- Icons by [Lucide](https://lucide.dev/)

---

**Made with â¤ï¸ for BuildFast Assignment**
